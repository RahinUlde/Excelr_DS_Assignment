{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2a92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b8a96ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1fdf01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/RahinUlde/DataSets/refs/heads/main/Alphabets_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7aca6",
   "metadata": {},
   "source": [
    "# Data understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3662dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff341f5d-2513-4366-aea1-acc3ba503cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885d252d-e22f-4f7b-9f37-341378ff35a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    26\n",
       "xbox      16\n",
       "ybox      16\n",
       "width     16\n",
       "height    16\n",
       "onpix     16\n",
       "xbar      16\n",
       "ybar      16\n",
       "x2bar     16\n",
       "y2bar     16\n",
       "xybar     16\n",
       "x2ybar    16\n",
       "xy2bar    16\n",
       "xedge     16\n",
       "xedgey    16\n",
       "yedge     16\n",
       "yedgex    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "997818fc-3ae3-430d-818c-94a604eec6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T', 'I', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'M', 'X', 'O', 'R',\n",
       "       'F', 'C', 'H', 'W', 'L', 'P', 'E', 'V', 'Y', 'Q', 'U', 'K', 'Z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42eba326-45d3-46f0-99fc-b061d0b8af30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter\n",
       "U    813\n",
       "D    805\n",
       "P    803\n",
       "T    796\n",
       "M    792\n",
       "A    789\n",
       "X    787\n",
       "Y    786\n",
       "N    783\n",
       "Q    783\n",
       "F    775\n",
       "G    773\n",
       "E    768\n",
       "B    766\n",
       "V    764\n",
       "L    761\n",
       "R    758\n",
       "I    755\n",
       "O    753\n",
       "W    752\n",
       "S    748\n",
       "J    747\n",
       "K    739\n",
       "C    736\n",
       "H    734\n",
       "Z    734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d689f",
   "metadata": {},
   "source": [
    "# Encoding (LabelEncoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60d759d0-8352-4332-be7c-2f1aa7e6dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e88c11d-356f-4d9c-ad52-960f0601e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode letter labels to integers\n",
    "le = LabelEncoder()\n",
    "df['letter'] = le.fit_transform(df['letter'])  # e.g., A=0, B=1, ..., Z=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39e48fb2-200d-431a-aec3-385f80d4a831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          19     2     8      3       5      1     8    13      0      6   \n",
       "1           8     5    12      3       7      2    10     5      5      4   \n",
       "2           3     4    11      6       8      6    10     6      2      6   \n",
       "3          13     7    11      6       6      3     5     9      4      6   \n",
       "4           6     2     1      3       1      1     8     6      6      6   \n",
       "...       ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995       3     2     2      3       3      2     7     7      7      6   \n",
       "19996       2     7    10      8       8      4     4     8      6      9   \n",
       "19997      19     6     9      6       7      5     6    11      3      7   \n",
       "19998      18     2     3      4       2      1     8     7      2      6   \n",
       "19999       0     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622fbf0",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00162f00-cb07-49d9-899b-c347865eb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ca93cf8-992f-4c71-97ad-b952a48448db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate indipendent features and target column \n",
    "X = df.drop('letter', axis=1)\n",
    "y = df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c750144-50ec-4eff-b7b5-229884a45d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a06f2e66-89aa-42ca-ba3e-c6d32f74294c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0576983 ,  0.29187713, -1.05327668, ..., -0.21908163,\n",
       "        -1.4381527 ,  0.12291107],\n",
       "       [ 0.51038497,  1.5023577 , -1.05327668, ..., -0.21908163,\n",
       "         0.12008142,  1.35944092],\n",
       "       [-0.01230945,  1.19973756,  0.43590966, ..., -0.8656262 ,\n",
       "        -0.26947711,  0.74117599],\n",
       "       ...,\n",
       "       [ 1.03307939,  0.59449727,  0.43590966, ...,  2.36709667,\n",
       "        -0.65903564, -2.35014863],\n",
       "       [-1.0576983 , -1.22122359, -0.55688123, ...,  0.42746295,\n",
       "         0.50963994,  0.12291107],\n",
       "       [-0.01230945,  0.59449727,  0.43590966, ..., -0.8656262 ,\n",
       "        -0.65903564,  0.12291107]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf22676-c120-45c3-9818-f800790cfa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         8\n",
       "2         3\n",
       "3        13\n",
       "4         6\n",
       "         ..\n",
       "19995     3\n",
       "19996     2\n",
       "19997    19\n",
       "19998    18\n",
       "19999     0\n",
       "Name: letter, Length: 20000, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753e7a4",
   "metadata": {},
   "source": [
    "# Spliting Data in traning and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f43265dd-75d7-4cb9-b69f-dddb1500bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47577997-54df-4548-8fce-ab5658b496ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f427357b-9380-4a3f-9913-7ac2c1cb893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (16000, 16)\n",
      "Test set size: (4000, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4477fd5",
   "metadata": {},
   "source": [
    "# Building Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ac361b4-c49d-463c-902f-c0819b0e3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Dense: to add layers(hidden, output)\n",
    "from tensorflow.keras import Sequential\n",
    "# Sequential: to add layers in sequence, to initialize ann model i.e. initially random weight will be assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e229e8a-83f5-41de-8777-32eb2053be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of features and classes\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f10feefb-dc76-4db3-a7b5-ffbf30e3aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='relu', input_shape=(input_dim,)))  # First hidden layer\n",
    "model.add(Dense(units=num_classes, activation='softmax'))  # Output layer for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed7212be-d018-45eb-977d-4c5b2eded7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='sparse_categorical_crossentropy',  # correct for integer multiclass labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e00f70b8-02d1-4aab-9f78-da946825371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0307 - loss: 3.4703 - val_accuracy: 0.0431 - val_loss: 3.4641\n",
      "Epoch 2/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: 3.4516 - val_accuracy: 0.0437 - val_loss: 3.4619\n",
      "Epoch 3/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0311 - loss: 3.4500 - val_accuracy: 0.0444 - val_loss: 3.4596\n",
      "Epoch 4/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0324 - loss: 3.4512 - val_accuracy: 0.0444 - val_loss: 3.4574\n",
      "Epoch 5/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0353 - loss: 3.4541 - val_accuracy: 0.0444 - val_loss: 3.4551\n",
      "Epoch 6/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0366 - loss: 3.4478 - val_accuracy: 0.0444 - val_loss: 3.4528\n",
      "Epoch 7/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: 3.4381 - val_accuracy: 0.0437 - val_loss: 3.4506\n",
      "Epoch 8/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0369 - loss: 3.4500 - val_accuracy: 0.0437 - val_loss: 3.4484\n",
      "Epoch 9/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0362 - loss: 3.4383 - val_accuracy: 0.0437 - val_loss: 3.4462\n",
      "Epoch 10/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0398 - loss: 3.4399 - val_accuracy: 0.0444 - val_loss: 3.4440\n",
      "Epoch 11/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0372 - loss: 3.4348 - val_accuracy: 0.0437 - val_loss: 3.4418\n",
      "Epoch 12/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0387 - loss: 3.4420 - val_accuracy: 0.0444 - val_loss: 3.4396\n",
      "Epoch 13/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0351 - loss: 3.4412 - val_accuracy: 0.0444 - val_loss: 3.4374\n",
      "Epoch 14/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0403 - loss: 3.4314 - val_accuracy: 0.0444 - val_loss: 3.4352\n",
      "Epoch 15/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0402 - loss: 3.4271 - val_accuracy: 0.0444 - val_loss: 3.4330\n",
      "Epoch 16/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0353 - loss: 3.4367 - val_accuracy: 0.0450 - val_loss: 3.4309\n",
      "Epoch 17/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0412 - loss: 3.4154 - val_accuracy: 0.0450 - val_loss: 3.4287\n",
      "Epoch 18/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: 3.4190 - val_accuracy: 0.0450 - val_loss: 3.4266\n",
      "Epoch 19/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0406 - loss: 3.4141 - val_accuracy: 0.0456 - val_loss: 3.4245\n",
      "Epoch 20/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0412 - loss: 3.4099 - val_accuracy: 0.0463 - val_loss: 3.4224\n",
      "Epoch 21/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0387 - loss: 3.4135 - val_accuracy: 0.0463 - val_loss: 3.4202\n",
      "Epoch 22/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0393 - loss: 3.4173 - val_accuracy: 0.0456 - val_loss: 3.4181\n",
      "Epoch 23/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0416 - loss: 3.4148 - val_accuracy: 0.0456 - val_loss: 3.4161\n",
      "Epoch 24/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0396 - loss: 3.4152 - val_accuracy: 0.0463 - val_loss: 3.4140\n",
      "Epoch 25/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0405 - loss: 3.4071 - val_accuracy: 0.0463 - val_loss: 3.4119\n",
      "Epoch 26/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0446 - loss: 3.4051 - val_accuracy: 0.0469 - val_loss: 3.4098\n",
      "Epoch 27/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0425 - loss: 3.4000 - val_accuracy: 0.0469 - val_loss: 3.4078\n",
      "Epoch 28/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0443 - loss: 3.4079 - val_accuracy: 0.0469 - val_loss: 3.4057\n",
      "Epoch 29/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0432 - loss: 3.4001 - val_accuracy: 0.0469 - val_loss: 3.4037\n",
      "Epoch 30/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0436 - loss: 3.3896 - val_accuracy: 0.0469 - val_loss: 3.4016\n",
      "Epoch 31/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0440 - loss: 3.3978 - val_accuracy: 0.0481 - val_loss: 3.3996\n",
      "Epoch 32/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0416 - loss: 3.3987 - val_accuracy: 0.0481 - val_loss: 3.3976\n",
      "Epoch 33/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0433 - loss: 3.3908 - val_accuracy: 0.0481 - val_loss: 3.3956\n",
      "Epoch 34/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0460 - loss: 3.3952 - val_accuracy: 0.0487 - val_loss: 3.3936\n",
      "Epoch 35/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0471 - loss: 3.3854 - val_accuracy: 0.0500 - val_loss: 3.3916\n",
      "Epoch 36/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0468 - loss: 3.3849 - val_accuracy: 0.0506 - val_loss: 3.3896\n",
      "Epoch 37/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0481 - loss: 3.3800 - val_accuracy: 0.0512 - val_loss: 3.3876\n",
      "Epoch 38/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0459 - loss: 3.3847 - val_accuracy: 0.0519 - val_loss: 3.3856\n",
      "Epoch 39/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0498 - loss: 3.3756 - val_accuracy: 0.0525 - val_loss: 3.3836\n",
      "Epoch 40/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0498 - loss: 3.3705 - val_accuracy: 0.0525 - val_loss: 3.3817\n",
      "Epoch 41/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0438 - loss: 3.3806 - val_accuracy: 0.0525 - val_loss: 3.3797\n",
      "Epoch 42/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0502 - loss: 3.3674 - val_accuracy: 0.0531 - val_loss: 3.3777\n",
      "Epoch 43/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0492 - loss: 3.3810 - val_accuracy: 0.0544 - val_loss: 3.3758\n",
      "Epoch 44/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0496 - loss: 3.3727 - val_accuracy: 0.0544 - val_loss: 3.3739\n",
      "Epoch 45/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0501 - loss: 3.3644 - val_accuracy: 0.0538 - val_loss: 3.3719\n",
      "Epoch 46/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0496 - loss: 3.3747 - val_accuracy: 0.0556 - val_loss: 3.3700\n",
      "Epoch 47/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0513 - loss: 3.3709 - val_accuracy: 0.0562 - val_loss: 3.3680\n",
      "Epoch 48/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0530 - loss: 3.3613 - val_accuracy: 0.0569 - val_loss: 3.3661\n",
      "Epoch 49/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0511 - loss: 3.3572 - val_accuracy: 0.0569 - val_loss: 3.3642\n",
      "Epoch 50/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0525 - loss: 3.3633 - val_accuracy: 0.0575 - val_loss: 3.3623\n",
      "Epoch 51/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0526 - loss: 3.3487 - val_accuracy: 0.0569 - val_loss: 3.3604\n",
      "Epoch 52/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0550 - loss: 3.3545 - val_accuracy: 0.0569 - val_loss: 3.3585\n",
      "Epoch 53/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0484 - loss: 3.3590 - val_accuracy: 0.0575 - val_loss: 3.3567\n",
      "Epoch 54/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0524 - loss: 3.3548 - val_accuracy: 0.0575 - val_loss: 3.3548\n",
      "Epoch 55/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0524 - loss: 3.3455 - val_accuracy: 0.0581 - val_loss: 3.3529\n",
      "Epoch 56/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0509 - loss: 3.3527 - val_accuracy: 0.0594 - val_loss: 3.3511\n",
      "Epoch 57/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0536 - loss: 3.3471 - val_accuracy: 0.0600 - val_loss: 3.3492\n",
      "Epoch 58/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0547 - loss: 3.3469 - val_accuracy: 0.0594 - val_loss: 3.3474\n",
      "Epoch 59/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0545 - loss: 3.3522 - val_accuracy: 0.0594 - val_loss: 3.3455\n",
      "Epoch 60/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0549 - loss: 3.3441 - val_accuracy: 0.0594 - val_loss: 3.3437\n",
      "Epoch 61/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0538 - loss: 3.3456 - val_accuracy: 0.0600 - val_loss: 3.3419\n",
      "Epoch 62/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0559 - loss: 3.3316 - val_accuracy: 0.0613 - val_loss: 3.3400\n",
      "Epoch 63/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0573 - loss: 3.3327 - val_accuracy: 0.0619 - val_loss: 3.3382\n",
      "Epoch 64/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0536 - loss: 3.3368 - val_accuracy: 0.0631 - val_loss: 3.3364\n",
      "Epoch 65/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0590 - loss: 3.3287 - val_accuracy: 0.0637 - val_loss: 3.3346\n",
      "Epoch 66/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0543 - loss: 3.3320 - val_accuracy: 0.0637 - val_loss: 3.3328\n",
      "Epoch 67/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0588 - loss: 3.3287 - val_accuracy: 0.0637 - val_loss: 3.3310\n",
      "Epoch 68/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0607 - loss: 3.3275 - val_accuracy: 0.0644 - val_loss: 3.3292\n",
      "Epoch 69/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0571 - loss: 3.3298 - val_accuracy: 0.0644 - val_loss: 3.3274\n",
      "Epoch 70/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0600 - loss: 3.3189 - val_accuracy: 0.0650 - val_loss: 3.3256\n",
      "Epoch 71/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0584 - loss: 3.3204 - val_accuracy: 0.0656 - val_loss: 3.3239\n",
      "Epoch 72/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0577 - loss: 3.3217 - val_accuracy: 0.0669 - val_loss: 3.3221\n",
      "Epoch 73/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0606 - loss: 3.3137 - val_accuracy: 0.0681 - val_loss: 3.3204\n",
      "Epoch 74/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0627 - loss: 3.3128 - val_accuracy: 0.0688 - val_loss: 3.3186\n",
      "Epoch 75/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0585 - loss: 3.3146 - val_accuracy: 0.0694 - val_loss: 3.3168\n",
      "Epoch 76/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0636 - loss: 3.3099 - val_accuracy: 0.0700 - val_loss: 3.3151\n",
      "Epoch 77/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0611 - loss: 3.3142 - val_accuracy: 0.0712 - val_loss: 3.3133\n",
      "Epoch 78/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0627 - loss: 3.3112 - val_accuracy: 0.0712 - val_loss: 3.3116\n",
      "Epoch 79/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0608 - loss: 3.3134 - val_accuracy: 0.0719 - val_loss: 3.3099\n",
      "Epoch 80/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0617 - loss: 3.3088 - val_accuracy: 0.0725 - val_loss: 3.3081\n",
      "Epoch 81/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0656 - loss: 3.3037 - val_accuracy: 0.0737 - val_loss: 3.3064\n",
      "Epoch 82/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0636 - loss: 3.2950 - val_accuracy: 0.0737 - val_loss: 3.3047\n",
      "Epoch 83/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0643 - loss: 3.3030 - val_accuracy: 0.0731 - val_loss: 3.3030\n",
      "Epoch 84/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0623 - loss: 3.3028 - val_accuracy: 0.0737 - val_loss: 3.3013\n",
      "Epoch 85/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0638 - loss: 3.2986 - val_accuracy: 0.0750 - val_loss: 3.2996\n",
      "Epoch 86/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0620 - loss: 3.2998 - val_accuracy: 0.0756 - val_loss: 3.2979\n",
      "Epoch 87/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0661 - loss: 3.2920 - val_accuracy: 0.0756 - val_loss: 3.2963\n",
      "Epoch 88/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0660 - loss: 3.2988 - val_accuracy: 0.0750 - val_loss: 3.2946\n",
      "Epoch 89/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0674 - loss: 3.2924 - val_accuracy: 0.0756 - val_loss: 3.2929\n",
      "Epoch 90/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0682 - loss: 3.2911 - val_accuracy: 0.0769 - val_loss: 3.2913\n",
      "Epoch 91/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0712 - loss: 3.2864 - val_accuracy: 0.0781 - val_loss: 3.2896\n",
      "Epoch 92/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0695 - loss: 3.2926 - val_accuracy: 0.0794 - val_loss: 3.2880\n",
      "Epoch 93/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0695 - loss: 3.2860 - val_accuracy: 0.0806 - val_loss: 3.2863\n",
      "Epoch 94/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0667 - loss: 3.2882 - val_accuracy: 0.0806 - val_loss: 3.2847\n",
      "Epoch 95/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0654 - loss: 3.2934 - val_accuracy: 0.0812 - val_loss: 3.2830\n",
      "Epoch 96/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0701 - loss: 3.2741 - val_accuracy: 0.0812 - val_loss: 3.2814\n",
      "Epoch 97/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0687 - loss: 3.2818 - val_accuracy: 0.0812 - val_loss: 3.2797\n",
      "Epoch 98/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0718 - loss: 3.2724 - val_accuracy: 0.0812 - val_loss: 3.2781\n",
      "Epoch 99/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0748 - loss: 3.2670 - val_accuracy: 0.0806 - val_loss: 3.2765\n",
      "Epoch 100/100\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0739 - loss: 3.2727 - val_accuracy: 0.0806 - val_loss: 3.2749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c2c9e62c10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "174a1d59-40df-4935-93e4-1d074661f580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0694 - loss: 3.2833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.2803943157196045, 0.07000000029802322]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8663199c-6b05-4155-b556-d1aa816d8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06388964, 0.02815257, 0.03587206, ..., 0.04532495, 0.03746849,\n",
       "        0.02819142],\n",
       "       [0.04075314, 0.03299462, 0.04697474, ..., 0.01987459, 0.04835592,\n",
       "        0.02392696],\n",
       "       [0.03549813, 0.05452088, 0.03791682, ..., 0.01998631, 0.03715852,\n",
       "        0.04080146],\n",
       "       ...,\n",
       "       [0.0396196 , 0.04930061, 0.03168811, ..., 0.02943915, 0.04109868,\n",
       "        0.02927354],\n",
       "       [0.04312069, 0.018085  , 0.08012687, ..., 0.0178814 , 0.02130149,\n",
       "        0.05967284],\n",
       "       [0.0320487 , 0.02972574, 0.09147229, ..., 0.01307131, 0.02472899,\n",
       "        0.02822188]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict classes\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred_prob\n",
    "#y_pred_classes = y_pred.argmax(axis=1)  # Get predicted class index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fee542b7-39c1-4d2c-a234-8b08753f1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to predicted class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c62a4b3-e4ae-40f5-9bb4-55fe9486299f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 11, 15, ..., 21, 16, 16], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e8354b2-4ce5-4e31-8a64-4e0772149bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "027e9fcd-d4fe-40e6-b64b-7380a0d48626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.53      0.60      0.56       158\n",
      "           B       0.00      0.00      0.00       153\n",
      "           C       0.00      0.00      0.00       147\n",
      "           D       0.01      0.06      0.02       161\n",
      "           E       0.00      0.00      0.00       154\n",
      "           F       0.00      0.00      0.00       155\n",
      "           G       0.00      0.00      0.00       155\n",
      "           H       0.00      0.00      0.00       147\n",
      "           I       0.00      0.00      0.00       151\n",
      "           J       0.06      0.05      0.05       149\n",
      "           K       0.01      0.02      0.01       148\n",
      "           L       0.09      0.05      0.07       152\n",
      "           M       0.00      0.00      0.00       158\n",
      "           N       0.00      0.00      0.00       157\n",
      "           O       0.00      0.00      0.00       150\n",
      "           P       0.09      0.42      0.15       161\n",
      "           Q       0.15      0.28      0.19       157\n",
      "           R       0.01      0.01      0.01       151\n",
      "           S       0.03      0.03      0.03       150\n",
      "           T       0.03      0.01      0.01       159\n",
      "           U       0.06      0.21      0.09       163\n",
      "           V       0.01      0.01      0.01       153\n",
      "           W       0.00      0.00      0.00       150\n",
      "           X       0.00      0.00      0.00       157\n",
      "           Y       0.00      0.00      0.00       157\n",
      "           Z       0.05      0.01      0.02       147\n",
      "\n",
      "    accuracy                           0.07      4000\n",
      "   macro avg       0.04      0.07      0.05      4000\n",
      "weighted avg       0.04      0.07      0.05      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb51cf",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a8b8d8f-1ba3-4715-a746-5a7e053dd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf70b72c-1a27-42b8-be9c-fc638a9d732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8213e4f-579b-43bb-9d0b-9fa9d4c1bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Wrap model in a function\n",
    "def create_model(hidden_layers=1, neurons=32, activation='relu', optimizer='adam', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(26, activation='softmax'))  # 26 classes (A-Z)\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "567056de-dabb-4353-b237-40e0776db13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create KerasClassifier\n",
    "model = KerasClassifier(model=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70de4d8f-85df-45cf-9306-5461187cf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define hyperparameter grid\n",
    "param_dist = {\n",
    "    'model__hidden_layers': [1, 2],\n",
    "    'model__neurons': [32, 64, 128],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__optimizer': ['adam', 'sgd'],\n",
    "    'model__learning_rate': [0.01, 0.001],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d791939e-bb0c-416f-9578-9961392f12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Run RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=5, cv=3, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec1f2bf4-4145-4fa4-a167-40631e36b785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "random_search_result = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8f70206-a3e2-48ae-a367-a0ffdae7025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9066873391247996\n",
      "Best Params: {'model__optimizer': 'adam', 'model__neurons': 128, 'model__learning_rate': 0.01, 'model__hidden_layers': 2, 'model__activation': 'tanh', 'epochs': 20, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Print best results\n",
    "print(\"Best Score:\", random_search_result.best_score_)\n",
    "print(\"Best Params:\", random_search_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09d051-8441-4bbd-9a43-4bc44d63e89f",
   "metadata": {},
   "source": [
    "# Final model using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07fa1931-6ac9-4d8a-85f6-1c2c68359cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28c7f56a-75f9-47b1-8357-899f5db09f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Sequential()\n",
    "final_model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "final_model.add(Dense(64, activation='relu'))  # second hidden layer (since hidden_layers=2)\n",
    "final_model.add(Dense(26, activation='softmax'))  # output layer for 26 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c50d5be6-f888-42a4-9654-3e1f01cf1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)  # best optimizer and learning rate\n",
    "final_model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bde78b5-ea5e-4015-851b-55de9e1e88ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2853 - loss: 2.6480 - val_accuracy: 0.6775 - val_loss: 1.1957\n",
      "Epoch 2/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 1.0616 - val_accuracy: 0.7694 - val_loss: 0.8438\n",
      "Epoch 3/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.7845 - val_accuracy: 0.8025 - val_loss: 0.7006\n",
      "Epoch 4/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.6352 - val_accuracy: 0.8294 - val_loss: 0.6103\n",
      "Epoch 5/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.5553 - val_accuracy: 0.8594 - val_loss: 0.5341\n",
      "Epoch 6/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.4957 - val_accuracy: 0.8731 - val_loss: 0.4824\n",
      "Epoch 7/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.4446 - val_accuracy: 0.8681 - val_loss: 0.4538\n",
      "Epoch 8/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.4019 - val_accuracy: 0.8706 - val_loss: 0.4251\n",
      "Epoch 9/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3693 - val_accuracy: 0.8881 - val_loss: 0.3815\n",
      "Epoch 10/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.3528 - val_accuracy: 0.8956 - val_loss: 0.3639\n",
      "Epoch 11/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9086 - loss: 0.3167 - val_accuracy: 0.8988 - val_loss: 0.3470\n",
      "Epoch 12/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.3006 - val_accuracy: 0.9031 - val_loss: 0.3217\n",
      "Epoch 13/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9204 - loss: 0.2795 - val_accuracy: 0.9094 - val_loss: 0.3127\n",
      "Epoch 14/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9310 - loss: 0.2527 - val_accuracy: 0.9081 - val_loss: 0.3012\n",
      "Epoch 15/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9247 - loss: 0.2525 - val_accuracy: 0.9175 - val_loss: 0.2840\n",
      "Epoch 16/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 0.2281 - val_accuracy: 0.9169 - val_loss: 0.2703\n",
      "Epoch 17/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.2132 - val_accuracy: 0.9244 - val_loss: 0.2643\n",
      "Epoch 18/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.2088 - val_accuracy: 0.9231 - val_loss: 0.2631\n",
      "Epoch 19/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.1977 - val_accuracy: 0.9169 - val_loss: 0.2552\n",
      "Epoch 20/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1853 - val_accuracy: 0.9256 - val_loss: 0.2402\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = final_model.fit(X_train, y_train,\n",
    "                          validation_split=0.1,  # keep 10% of training data for validation\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34eb6213-f82c-4928-a7e0-666beb22f7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0459011e-06, 3.9263174e-02, 6.5687001e-13, ..., 1.7199396e-05,\n",
       "        2.2854167e-10, 4.3356954e-09],\n",
       "       [3.9645132e-09, 5.0525561e-18, 3.0539612e-15, ..., 1.8151018e-15,\n",
       "        4.4035340e-13, 1.0714580e-20],\n",
       "       [7.2198326e-08, 9.9246830e-01, 7.8589121e-11, ..., 4.8142727e-08,\n",
       "        1.0935532e-08, 3.6170670e-05],\n",
       "       ...,\n",
       "       [3.5692648e-07, 4.2533561e-08, 7.3786956e-11, ..., 9.8072219e-01,\n",
       "        7.9347320e-11, 6.8309872e-11],\n",
       "       [2.3061625e-08, 1.6380197e-13, 1.7945149e-05, ..., 3.2054128e-08,\n",
       "        1.8153652e-07, 2.5024850e-12],\n",
       "       [1.5655367e-12, 6.3803165e-24, 7.0859812e-08, ..., 3.0575414e-15,\n",
       "        5.2985200e-07, 2.6599069e-22]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "y_pred_final_probs = final_model.predict(X_test)\n",
    "y_pred_final_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b8726e1-8997-40c3-b13b-04a0226c95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to class indices (0–25)\n",
    "y_pred_final = np.argmax(y_pred_final_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcfab86e-e15b-4160-a370-f8b4048094fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 12,  1, ..., 23, 16, 20], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "472cb862-fa11-479a-aed2-cdc38ea5fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9313\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_final)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84f371fb-20d7-4684-9897-ce0c9fc65058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       158\n",
      "           1       0.86      0.93      0.89       153\n",
      "           2       0.91      0.99      0.95       147\n",
      "           3       0.90      0.93      0.91       161\n",
      "           4       0.90      0.90      0.90       154\n",
      "           5       0.93      0.91      0.92       155\n",
      "           6       0.96      0.88      0.92       155\n",
      "           7       0.94      0.80      0.86       147\n",
      "           8       0.97      0.89      0.93       151\n",
      "           9       0.92      0.94      0.93       149\n",
      "          10       0.90      0.89      0.89       148\n",
      "          11       0.99      0.93      0.96       152\n",
      "          12       0.99      0.96      0.97       158\n",
      "          13       0.93      0.91      0.92       157\n",
      "          14       0.96      0.91      0.94       150\n",
      "          15       0.95      0.96      0.95       161\n",
      "          16       0.94      0.98      0.96       157\n",
      "          17       0.80      0.90      0.84       151\n",
      "          18       0.94      0.89      0.91       150\n",
      "          19       0.93      0.95      0.94       159\n",
      "          20       0.99      0.99      0.99       163\n",
      "          21       0.95      0.95      0.95       153\n",
      "          22       0.98      0.98      0.98       150\n",
      "          23       0.87      0.92      0.89       157\n",
      "          24       0.94      0.96      0.95       157\n",
      "          25       0.96      0.97      0.96       147\n",
      "\n",
      "    accuracy                           0.93      4000\n",
      "   macro avg       0.93      0.93      0.93      4000\n",
      "weighted avg       0.93      0.93      0.93      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8330e1df-a19f-4a38-a3c2-d5a5ca4f0103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1724\n",
      "[0.18048977851867676, 0.948312520980835]\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.2210\n",
      "[0.22691349685192108, 0.9312499761581421]\n"
     ]
    }
   ],
   "source": [
    "print(final_model.evaluate(X_train,y_train))\n",
    "print(final_model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d0bbc-1620-4985-9461-ff4447629085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
